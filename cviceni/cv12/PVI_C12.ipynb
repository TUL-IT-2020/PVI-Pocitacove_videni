{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/pytel/.local/lib/python3.12/site-packages (from -r ../../pip-dependencies.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: scipy in /home/pytel/.local/lib/python3.12/site-packages (from -r ../../pip-dependencies.txt (line 2)) (1.14.1)\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from -r ../../pip-dependencies.txt (line 3)) (10.2.0)\n",
      "Requirement already satisfied: easyocr in /home/pytel/.local/lib/python3.12/site-packages (from -r ../../pip-dependencies.txt (line 4)) (1.7.1)\n",
      "Requirement already satisfied: webcolors in /home/pytel/.local/lib/python3.12/site-packages (from -r ../../pip-dependencies.txt (line 5)) (24.8.0)\n",
      "Requirement already satisfied: matplotlib in /home/pytel/.local/lib/python3.12/site-packages (from -r ../../pip-dependencies.txt (line 6)) (3.9.2)\n",
      "Requirement already satisfied: scikit-image in /home/pytel/.local/lib/python3.12/site-packages (from -r ../../pip-dependencies.txt (line 7)) (0.24.0)\n",
      "Requirement already satisfied: opencv-python in /home/pytel/.local/lib/python3.12/site-packages (from -r ../../pip-dependencies.txt (line 8)) (4.10.0.84)\n",
      "Requirement already satisfied: transformers in /home/pytel/.local/lib/python3.12/site-packages (from -r ../../pip-dependencies.txt (line 9)) (4.46.3)\n",
      "Requirement already satisfied: datasets in /home/pytel/.local/lib/python3.12/site-packages (from -r ../../pip-dependencies.txt (line 10)) (3.1.0)\n",
      "Requirement already satisfied: torch in /home/pytel/.local/lib/python3.12/site-packages (from -r ../../pip-dependencies.txt (line 11)) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.5 in /home/pytel/.local/lib/python3.12/site-packages (from easyocr->-r ../../pip-dependencies.txt (line 4)) (0.19.1)\n",
      "Requirement already satisfied: opencv-python-headless in /home/pytel/.local/lib/python3.12/site-packages (from easyocr->-r ../../pip-dependencies.txt (line 4)) (4.10.0.84)\n",
      "Requirement already satisfied: python-bidi in /home/pytel/.local/lib/python3.12/site-packages (from easyocr->-r ../../pip-dependencies.txt (line 4)) (0.6.0)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from easyocr->-r ../../pip-dependencies.txt (line 4)) (6.0.1)\n",
      "Requirement already satisfied: Shapely in /home/pytel/.local/lib/python3.12/site-packages (from easyocr->-r ../../pip-dependencies.txt (line 4)) (2.0.6)\n",
      "Requirement already satisfied: pyclipper in /home/pytel/.local/lib/python3.12/site-packages (from easyocr->-r ../../pip-dependencies.txt (line 4)) (1.3.0.post5)\n",
      "Requirement already satisfied: ninja in /home/pytel/.local/lib/python3.12/site-packages (from easyocr->-r ../../pip-dependencies.txt (line 4)) (1.11.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/pytel/.local/lib/python3.12/site-packages (from matplotlib->-r ../../pip-dependencies.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/pytel/.local/lib/python3.12/site-packages (from matplotlib->-r ../../pip-dependencies.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/pytel/.local/lib/python3.12/site-packages (from matplotlib->-r ../../pip-dependencies.txt (line 6)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/pytel/.local/lib/python3.12/site-packages (from matplotlib->-r ../../pip-dependencies.txt (line 6)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from matplotlib->-r ../../pip-dependencies.txt (line 6)) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->-r ../../pip-dependencies.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib->-r ../../pip-dependencies.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/pytel/.local/lib/python3.12/site-packages (from scikit-image->-r ../../pip-dependencies.txt (line 7)) (3.3)\n",
      "Requirement already satisfied: imageio>=2.33 in /home/pytel/.local/lib/python3.12/site-packages (from scikit-image->-r ../../pip-dependencies.txt (line 7)) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/pytel/.local/lib/python3.12/site-packages (from scikit-image->-r ../../pip-dependencies.txt (line 7)) (2024.8.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/pytel/.local/lib/python3.12/site-packages (from scikit-image->-r ../../pip-dependencies.txt (line 7)) (0.4)\n",
      "Requirement already satisfied: filelock in /home/pytel/.local/lib/python3.12/site-packages (from transformers->-r ../../pip-dependencies.txt (line 9)) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/pytel/.local/lib/python3.12/site-packages (from transformers->-r ../../pip-dependencies.txt (line 9)) (0.26.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/pytel/.local/lib/python3.12/site-packages (from transformers->-r ../../pip-dependencies.txt (line 9)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/pytel/.local/lib/python3.12/site-packages (from transformers->-r ../../pip-dependencies.txt (line 9)) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/pytel/.local/lib/python3.12/site-packages (from transformers->-r ../../pip-dependencies.txt (line 9)) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/pytel/.local/lib/python3.12/site-packages (from transformers->-r ../../pip-dependencies.txt (line 9)) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/pytel/.local/lib/python3.12/site-packages (from transformers->-r ../../pip-dependencies.txt (line 9)) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/pytel/.local/lib/python3.12/site-packages (from datasets->-r ../../pip-dependencies.txt (line 10)) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/pytel/.local/lib/python3.12/site-packages (from datasets->-r ../../pip-dependencies.txt (line 10)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/pytel/.local/lib/python3.12/site-packages (from datasets->-r ../../pip-dependencies.txt (line 10)) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/pytel/.local/lib/python3.12/site-packages (from datasets->-r ../../pip-dependencies.txt (line 10)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/pytel/.local/lib/python3.12/site-packages (from datasets->-r ../../pip-dependencies.txt (line 10)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/pytel/.local/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r ../../pip-dependencies.txt (line 10)) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/pytel/.local/lib/python3.12/site-packages (from datasets->-r ../../pip-dependencies.txt (line 10)) (3.11.7)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/lib/python3/dist-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (68.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/pytel/.local/lib/python3.12/site-packages (from torch->-r ../../pip-dependencies.txt (line 11)) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/pytel/.local/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r ../../pip-dependencies.txt (line 11)) (12.6.68)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/pytel/.local/lib/python3.12/site-packages (from aiohttp->datasets->-r ../../pip-dependencies.txt (line 10)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/pytel/.local/lib/python3.12/site-packages (from aiohttp->datasets->-r ../../pip-dependencies.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets->-r ../../pip-dependencies.txt (line 10)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/pytel/.local/lib/python3.12/site-packages (from aiohttp->datasets->-r ../../pip-dependencies.txt (line 10)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/pytel/.local/lib/python3.12/site-packages (from aiohttp->datasets->-r ../../pip-dependencies.txt (line 10)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/pytel/.local/lib/python3.12/site-packages (from aiohttp->datasets->-r ../../pip-dependencies.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/pytel/.local/lib/python3.12/site-packages (from aiohttp->datasets->-r ../../pip-dependencies.txt (line 10)) (1.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pytel/.local/lib/python3.12/site-packages (from requests->transformers->-r ../../pip-dependencies.txt (line 9)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers->-r ../../pip-dependencies.txt (line 9)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers->-r ../../pip-dependencies.txt (line 9)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers->-r ../../pip-dependencies.txt (line 9)) (2023.11.17)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets->-r ../../pip-dependencies.txt (line 10)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/pytel/.local/lib/python3.12/site-packages (from pandas->datasets->-r ../../pip-dependencies.txt (line 10)) (2024.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/pytel/.local/lib/python3.12/site-packages (from sympy->torch->-r ../../pip-dependencies.txt (line 11)) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../my_libs/')\n",
    "sys.path.append('../my_libs/img/')\n",
    "\n",
    "!{sys.executable} -m pip install -r ../../pip-dependencies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_libs.tools import *\n",
    "from my_libs.colors import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cvičení"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natrénujte a vyhodnoťte klasifikátor založený na hluboké neuronové síti, který \n",
    "bude  z  obrázku  člověka  určovat,  zda  se  jedná  o  dospělého  či  o  dítě.  Pro \n",
    "trénování a validaci využijte dataset children-vs-adults.zip. Klasifikátor by měl \n",
    "dosáhnout přesnosti (accuracy) alespoň 80 % na validační množině. \n",
    "\n",
    "### Poznámky\n",
    "Není to nezbytné, ale běh na GPU bude rychlejší než na CPU. Kód lze spustit na zdarma dostupných službách poskytujících GPU, např.: \n",
    "- [Google colab](https://colab.research.google.com/drive/16pBJQePbqkz3QFV54L4NIkOn1kwpuRrj) \n",
    "\n",
    "Můžete  použít  libovolnou  dostupnou  knihovnu  pro  práci  s  neuronovými sítěmi.  Doporučené  jsou PyTorch nebo Keras, které  jsou  dobře dokumentované se spoustou příkladů. \n",
    "\n",
    "Doporučený postup je tzv. transfer learning, tj. použití existujícího modelu a  jeho  přizpůsobení  na  novou  úlohu.  Příklady  transfer  learningu  jsou dostupné na Transfer learning v:\n",
    "- [Pytorch](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "- [Keras](https://keras.io/guides/transfer_learning/)\n",
    "\n",
    "Předtrénované  neuronové  sítě  pro  klasifikaci  obrázků  lze  vybírat  z  tzv. \n",
    "ZOO modelů. \n",
    "Knihovna modelů a datasetů:\n",
    "- [torchvision](https://pytorch.org/vision/stable/index.html)\n",
    "- [Pytorch timm](https://huggingface.co/docs/timm/quickstart)\n",
    "- [Keras](https://keras.io/api/applications/)\n",
    "\n",
    "Není nezbytné používat veké modely. Požadovaného skóre lze dosáhnout i s menšími  modely. Např.  předtrénovaný model  „resnet10t”  z  knihovny timm (PyTorch) dosahuje 80% přesnosti  již  po  `3`  epochách při `batch_size=100`  a  optimalizačním algoritmu  Adam  s  `learning_rate = 0.001`. \n",
    "Jedna epocha na CPU Ryzen 7 5700X trvá cca 21 s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uvažované modely\n",
    "Stažené z [Hugging Face](https://huggingface.co/models?pipeline_tag=image-classification&sort=trending&search=Microsoft+resnet)\n",
    "\n",
    "Z dílny Microsoftu:\n",
    "- [resnet-18](https://huggingface.co/microsoft/resnet-18)\n",
    "- [resnet-50](https://huggingface.co/microsoft/resnet-50)\n",
    "- [resnet-152](https://huggingface.co/microsoft/resnet-152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Výběr modelu a jeho modifikace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Načtení modelu a procesoru\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-18\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n",
    "\n",
    "# Nastavení modelu pro transfer learning\n",
    "if isinstance(model.classifier, torch.nn.Sequential):\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = torch.nn.Linear(in_features, 2)  # Binary classification (adult/children)\n",
    "else:\n",
    "    in_features = model.classifier.in_features\n",
    "    model.classifier = torch.nn.Linear(in_features, 2)  # Binary classification (adult/children)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametry\n",
    "batch_size = 100\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_pictures = 800\n",
    "folder = \"children_vs_adults\"\n",
    "train_folder = \"train\"\n",
    "test_folder = \"valid\"\n",
    "\n",
    "# Cesty k trénovacím a testovacím složkám\n",
    "train_path = os.path.join(folder, train_folder)\n",
    "test_path = os.path.join(folder, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Train path:  \u001b[0;34mchildren_vs_adults/train\u001b[0m\n",
      "Test path:  \u001b[0;34mchildren_vs_adults/valid\u001b[0m\n",
      "Number of training examples:  \u001b[0;34m680\u001b[0m\n",
      "Number of test examples:  \u001b[0;34m120\u001b[0m\n",
      "\n",
      "\u001b[0;32mDataset loaded successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Nastavení transformací pro dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "])\n",
    "\n",
    "# Načtení datasetu\n",
    "print(\"Loading the dataset...\")\n",
    "print(\"Train path: \", Blue + train_path + NC)\n",
    "print(\"Test path: \", Blue + test_path + NC)\n",
    "\n",
    "# Načtení datasetu\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Number of training examples: \", Blue + str(len(train_dataset)) + NC)\n",
    "print(\"Number of test examples: \", Blue + str(len(test_dataset)) + NC)\n",
    "\n",
    "print(\"\")\n",
    "if len(train_dataset) + len(test_dataset) != number_of_pictures:\n",
    "    print(\"Number of pictures in the dataset is not correct.\")\n",
    "    print(\"Expected number of pictures: \", number_of_pictures)\n",
    "    print(\"Number of pictures in the dataset: \", len(train_dataset) + len(test_dataset))\n",
    "    exit(1)\n",
    "else:\n",
    "    print(Green + \"Dataset loaded successfully.\" + NC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nastavení trénování"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper parameters:\n",
      "Batch size: \t \u001b[0;34m8\u001b[0m\n",
      "Learning rate: \t \u001b[0;34m0.0001\u001b[0m\n",
      "Usig device: \t \u001b[0;34mcpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "print(\"Hyper parameters:\")\n",
    "print(\"Batch size: \\t\", Blue + str(batch_size) + NC)\n",
    "print(\"Learning rate: \\t\", Blue + str(learning_rate) + NC)\n",
    "print(\"Usig device: \\t\", Blue + str(device) + NC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trénování modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/resnet/modeling_resnet.py:406\u001b[0m, in \u001b[0;36mResNetForImageClassification.forward\u001b[0;34m(self, pixel_values, labels, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Labels for computing the image classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    404\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 406\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpooler_output \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    410\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(pooled_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/resnet/modeling_resnet.py:345\u001b[0m, in \u001b[0;36mResNetModel.forward\u001b[0;34m(self, pixel_values, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    340\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    341\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    342\u001b[0m )\n\u001b[1;32m    343\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 345\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    348\u001b[0m     embedding_output, output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states, return_dict\u001b[38;5;241m=\u001b[39mreturn_dict\n\u001b[1;32m    349\u001b[0m )\n\u001b[1;32m    351\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/resnet/modeling_resnet.py:96\u001b[0m, in \u001b[0;36mResNetEmbeddings.forward\u001b[0;34m(self, pixel_values)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure that the channel dimension of the pixel values match with the one set in the configuration.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[1;32m     95\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder(pixel_values)\n\u001b[0;32m---> 96\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpooler\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedding\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/pooling.py:164\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_jit_internal.py:503\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/functional.py:796\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    795\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Vyhodnocení modelu\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).logits\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the model on the test images: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.figure()\n",
    "plt.plot(running_loss)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
